{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some notes on the inaugural project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally you did really well, and it was a treat to read your projects and different approaches to project. <br>\n",
    "But there where two recuring errors I would like to note and explain, and then I have some comments on style choices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recuring errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### np.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quite a few of you got into trouble using the np.max() function. This is quite understandable given that it looks like the obvious function to use, the problem can be shown by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(-1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is not what we intended. <br>\n",
    "The reason is that the np.max()-function is made to take an array as input and then compare all the elements of the array and return the largest. Thus in this case it compares -1 with nothing and returns -1. The 0 is interpreted as the axis argument.\n",
    "<br>\n",
    "This can be seen by looking at the documentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function amax in module numpy:\n",
      "\n",
      "amax(a, axis=None, out=None, keepdims=<no value>, initial=<no value>, where=<no value>)\n",
      "    Return the maximum of an array or maximum along an axis.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input data.\n",
      "    axis : None or int or tuple of ints, optional\n",
      "        Axis or axes along which to operate.  By default, flattened input is\n",
      "        used.\n",
      "    \n",
      "        .. versionadded:: 1.7.0\n",
      "    \n",
      "        If this is a tuple of ints, the maximum is selected over multiple axes,\n",
      "        instead of a single axis or all the axes as before.\n",
      "    out : ndarray, optional\n",
      "        Alternative output array in which to place the result.  Must\n",
      "        be of the same shape and buffer length as the expected output.\n",
      "        See `doc.ufuncs` (Section \"Output arguments\") for more details.\n",
      "    \n",
      "    keepdims : bool, optional\n",
      "        If this is set to True, the axes which are reduced are left\n",
      "        in the result as dimensions with size one. With this option,\n",
      "        the result will broadcast correctly against the input array.\n",
      "    \n",
      "        If the default value is passed, then `keepdims` will not be\n",
      "        passed through to the `amax` method of sub-classes of\n",
      "        `ndarray`, however any non-default value will be.  If the\n",
      "        sub-class' method does not implement `keepdims` any\n",
      "        exceptions will be raised.\n",
      "    \n",
      "    initial : scalar, optional\n",
      "        The minimum value of an output element. Must be present to allow\n",
      "        computation on empty slice. See `~numpy.ufunc.reduce` for details.\n",
      "    \n",
      "        .. versionadded:: 1.15.0\n",
      "    \n",
      "    where : array_like of bool, optional\n",
      "        Elements to compare for the maximum. See `~numpy.ufunc.reduce`\n",
      "        for details.\n",
      "    \n",
      "        .. versionadded:: 1.17.0\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    amax : ndarray or scalar\n",
      "        Maximum of `a`. If `axis` is None, the result is a scalar value.\n",
      "        If `axis` is given, the result is an array of dimension\n",
      "        ``a.ndim - 1``.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    amin :\n",
      "        The minimum value of an array along a given axis, propagating any NaNs.\n",
      "    nanmax :\n",
      "        The maximum value of an array along a given axis, ignoring any NaNs.\n",
      "    maximum :\n",
      "        Element-wise maximum of two arrays, propagating any NaNs.\n",
      "    fmax :\n",
      "        Element-wise maximum of two arrays, ignoring any NaNs.\n",
      "    argmax :\n",
      "        Return the indices of the maximum values.\n",
      "    \n",
      "    nanmin, minimum, fmin\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    NaN values are propagated, that is if at least one item is NaN, the\n",
      "    corresponding max value will be NaN as well. To ignore NaN values\n",
      "    (MATLAB behavior), please use nanmax.\n",
      "    \n",
      "    Don't use `amax` for element-wise comparison of 2 arrays; when\n",
      "    ``a.shape[0]`` is 2, ``maximum(a[0], a[1])`` is faster than\n",
      "    ``amax(a, axis=0)``.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.arange(4).reshape((2,2))\n",
      "    >>> a\n",
      "    array([[0, 1],\n",
      "           [2, 3]])\n",
      "    >>> np.amax(a)           # Maximum of the flattened array\n",
      "    3\n",
      "    >>> np.amax(a, axis=0)   # Maxima along the first axis\n",
      "    array([2, 3])\n",
      "    >>> np.amax(a, axis=1)   # Maxima along the second axis\n",
      "    array([1, 3])\n",
      "    >>> np.amax(a, where=[False, True], initial=-1, axis=0)\n",
      "    array([-1,  3])\n",
      "    >>> b = np.arange(5, dtype=float)\n",
      "    >>> b[2] = np.NaN\n",
      "    >>> np.amax(b)\n",
      "    nan\n",
      "    >>> np.amax(b, where=~np.isnan(b), initial=-1)\n",
      "    4.0\n",
      "    >>> np.nanmax(b)\n",
      "    4.0\n",
      "    \n",
      "    You can use an initial value to compute the maximum of an empty slice, or\n",
      "    to initialize it to a different value:\n",
      "    \n",
      "    >>> np.max([[-50], [10]], axis=-1, initial=0)\n",
      "    array([ 0, 10])\n",
      "    \n",
      "    Notice that the initial value is used as one of the elements for which the\n",
      "    maximum is determined, unlike for the default argument Python's max\n",
      "    function, which is only used for empty iterables.\n",
      "    \n",
      "    >>> np.max([5], initial=6)\n",
      "    6\n",
      "    >>> max([5], default=6)\n",
      "    5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.max) # This is an easy way to acces documentation\n",
    "#np.amax and np.max is the same function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So to make it work you'd have to the insert the values you want compared as a list:\n",
    "np.max([-1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But there are more functions that can do the job easier and works intuitively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(np.fmax(-1,0))\n",
    "print(max(-1,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of you got into trouble because of your use of global variables in functions, instead of passing them as arguments. <br>\n",
    "I would recomend when making larger projects that the variables you use in each function is an argument to the function, as this can be a gut-wrenching source of errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Style comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is some stuff I would recomend that you think about, but of course it a bit more subjective what kind of style you like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Less is more "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you can get the same results with the same precision in fewer lines, I would always recommend it. I makes your code easier to read and debug, and can save you a lot of time. <br>\n",
    "The easiest way to do this is whenever you're doing repetitive tasks, to make a function to pass multiple times. The main place where I noticed this, is problem 3) and 4). Since problem 4) is just 3) with a different parameter-value, I recommend that you harness the power of programming and make one function that solves both problems. I'ts recomended and good practice to reuse earlier defined functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unpacking results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a small thing but in the interest of writting fewer lines of code, I would just mention it: when unpacking a result into multiple variables, you can save some typing, using unpacking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3\n",
      "1 2 3\n",
      "1 2\n",
      "1 2\n"
     ]
    }
   ],
   "source": [
    "# Initiate some random data:\n",
    "result = [1,2,3]\n",
    "\n",
    "#These many lines of code:\n",
    "a = result[0]\n",
    "b = result[1]\n",
    "c = result[2]\n",
    "print(a,b,c)\n",
    "\n",
    "#Can be replaced with this:\n",
    "a,b,c = result\n",
    "print(a,b,c)\n",
    "\n",
    "# Or if you dont want to unpack the whole list:\n",
    "a, b = result[0],result[1]\n",
    "print(a,b)\n",
    "#although even this can be shorter:\n",
    "a, b = result[0:2]\n",
    "print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 4)\n",
      "<class 'tuple'>\n",
      "2 4\n"
     ]
    }
   ],
   "source": [
    "# You can also unpack this way when using functions which returns multiple outputs \n",
    "# (in reality it returns a tuple, but you can unpack it as multiple variables):\n",
    "def double_output_func(x1,x2):\n",
    "    '''\n",
    "    This function takes two arguments and returns the double of those arguments as a tuple\n",
    "    \n",
    "    arguments:\n",
    "        x1 (int/float) : a number to double\n",
    "        x2 (int/float) : a number to double\n",
    "        \n",
    "    returns:\n",
    "        (tuple): Two elements, the inputed arguments times 2\n",
    "    '''\n",
    "    x1_new = x1*2\n",
    "    x2_new = x2*2\n",
    "    return x1_new, x2_new\n",
    "\n",
    "res = double_output_func(1,2)\n",
    "print(res)\n",
    "print(type(res))\n",
    "\n",
    "res1, res2 = double_output_func(1,2)\n",
    "print(res1,res2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general convention, and what jeppe preferes, is using docstrings inside functions(as the double_output_func above). This might seem tedious to do some times but is really helpfull when you look at it later, and sticking with this style makes it faster to read, since you'll get used to commmon python documentation. Another added benefit is that you can reference your own documentation (which is again usefull when writing loads of code code, and you might forget the ordering of the arguments of a function you've defined a week ago):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function double_output_func in module __main__:\n",
      "\n",
      "double_output_func(x1, x2)\n",
      "    This function takes two arguments and returns the double of those arguments as a tuple\n",
      "    \n",
      "    arguments:\n",
      "        x1 (int/float) : a number to double\n",
      "        x2 (int/float) : a number to double\n",
      "        \n",
      "    returns:\n",
      "        (tuple): Two elements, the inputed arguments times 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(double_output_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes on Problem set 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This problemset focuses on lecture 8, loading and editing datasets, and requires some essential skills which will be necessary for you data analysis project.  <br>\n",
    "I've written some notes here, that I hope will be usefull so you don't have to rely on the answers only, if you have any questions you can write me at hms467@econ.ku.dk. If youre interested you can also see my (undocumented) take on the problem set at . Generally I would recomend using the [thread](https://github.com/NumEconCopenhagen/lectures-2020/issues) the Jeppe has suggested as it good to have the tips and tricks collected so everybody benefits from it. You can see earlier solves issues in the 'closed'-section. <br>\n",
    "I would recomend, if you have not already, that you start looking at the documentation when figuring out how to use the functions correctly, as it will be really beneficial for the dataproject that you are capable of this. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem: 2.1:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For loading denmarks statistics: see 3.1 in lecture 8 <br>\n",
    "For step 2: <br>\n",
    "If you're unsure how to use the .replace()-method, look up the [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.replace.html), I would recomend looking at the examples in the bottom. <br> \n",
    "(btw type(nah1.variable) and type(nah1.unit) are both pandas series, so you want to look at series.replace() documentation i have linked to, not DataFrame.replace() documentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Step 3:\n",
    "You need a boolean series that represents for each observation, whether the variable-column is recorded as Y, C, G, I, X or M. Then you can call all the obsevations in nah1 which statifies this condition. <br>\n",
    "Jeppe creates this by looping through var_dict. <br>\n",
    "I did it using the pandas series [.isin()-method](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.isin.html), the series you wanna use it on is: nah1.variable <br>\n",
    "You can also use the numpy function [isin()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.isin.html) <br>\n",
    "The sign: | btw means 'or', in case you've forgotten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For step 4, it should of course be: nah1.groupby(['variable','unit']).describe() not nah1_true. <br>\n",
    "If you wanna get really technical in you discussion, you can check out the documentation for [.describe()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.core.groupby.DataFrameGroupBy.describe.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 2.2**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, use the [documentaion](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html) <br>\n",
    "For using the .join()-method you can see 2.2.4 in lecture 8 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 3.1 and 3.2 there is not much to say, I would just recomend that you go through it carefuly, and experiment with the commands you don't understand. This is a good resource to go back to when doing the dataproject. <br>\n",
    "For 3.3 is get's a little trickier, I would recomend that you work systematically, for example: Merge pop and prices_long. Generate log variables. Generate log-diff-variables grouped on muncipalities. Plot the first figure. For the second figure it's easier to create and plot the variables in one line with the agg-method, as Jeppe suggested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concluding remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you've finished this problem set, you'll have had all the preparation you need, for starting on the Data Analysis Project, so I suggest you get started on it, if you haven't already started thinking about what kind of project you wanna do. <br>\n",
    "In the slides for exercise 7, I've listed possible datasources. Other than that, the best advice I can give you is to choose something you're interested in, but also to keep the proejct small (unless of course you're in quarantine and have plenty of time): loading some data, cleaning it, doing some transformations/calculation and plotting a few figures can take plenty of time because of the set of potential errors, and will likely be enough for good project as long as the quality is good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"excelling_in_data.jpeg\" style=\"width:400px;height:400px\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
